{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m810.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m775.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home2/oml4h/miniconda3/envs/plm_sars/lib/python3.7/site-packages (from transformers) (4.66.5)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.5.3.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m855.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install backend dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[3 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m ERROR: Ignored the following versions that require a different python version: 0.1.0 Requires-Python >=3.9; 0.1.1 Requires-Python >=3.9; 0.1.2 Requires-Python >=3.9; 0.1.3 Requires-Python >=3.9; 0.1.4 Requires-Python >=3.9; 0.1.5 Requires-Python >=3.9\n",
      "  \u001b[31m   \u001b[0m ERROR: Could not find a version that satisfies the requirement puccinialin (from versions: none)\n",
      "  \u001b[31m   \u001b[0m ERROR: No matching distribution found for puccinialin\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install backend dependencies\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3198491/2218898624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install transformers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEsmForMaskedLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT5EncoderModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDataCollatorForLanguageModeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaskedLMOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import sys, importlib\n",
    "module_name = \"Functions\"\n",
    "if module_name in sys.modules:\n",
    "    del sys.modules[module_name]\n",
    "Functions = importlib.import_module(module_name)\n",
    "\n",
    "from Functions import *\n",
    "\n",
    "import esm\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "from transformers import EsmForMaskedLM, T5EncoderModel,T5Tokenizer,DataCollatorForLanguageModeling\n",
    "from transformers.modeling_outputs import MaskedLMOutput\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, alphabet = esm.pretrained.load_model_and_alphabet('esm2_t36_3B_UR50D')\n",
    "model.eval()\n",
    "\n",
    "mod = EsmForMaskedLM.from_pretrained(modnam)\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    model =  model.to(device)\n",
    "    print(\"Transferred model to GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrez.email = \"sample@example.org\"\n",
    "\n",
    "# handle = Entrez.efetch(db=\"nucleotide\",\n",
    "#                        id=\"NC_045512.2\",\n",
    "#                        rettype=\"gb\",\n",
    "#                        retmode=\"gb\")\n",
    "# whole_sequence = SeqIO.read(handle, \"genbank\")\n",
    "model_layers = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = read_sequences_to_dict('/home2/oml4h/PLM_SARS-CoV-2/Sequences/huH3N2_HA_CDS.translated.fas')\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=list(sequences.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_indexed_muts = [m for m in get_reference_mutations(ref = sequences[ids[0]],mut = sequences[ids[len(ids)-1]]) if \"-\" not in m  ] \n",
    "K_indexed_muts = [m for m in get_mutations(sequences[ids[0]],sequences[ids[len(ids)-1]]) if \"del\" not in m and '-' not in m  ] \n",
    "print(\"K->J mutations\")\n",
    "print(K_indexed_muts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_dictionary  = {k:J_indexed_muts[i] for i,k in enumerate(K_indexed_muts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutations = {}\n",
    "Functions.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = \"Wuhan-Hu-1\"\n",
    "backbone = ids[len(ids)-1]\n",
    "all_mutations = {}\n",
    "mut_info=pd.DataFrame(columns=[\"Mutation\",\"rel_grammar\",\"rel_seq_grammar\",\"semanatic_score\",\"probability\",\"Backbone\"])\n",
    "\n",
    "reference_spike_sequence = sequences[backbone]\n",
    "#loop through each node in the tree except the last one (lineage of interest)\n",
    "for backbone_i in range(len(ids)-1):\n",
    "    backbone = ids[backbone_i]\n",
    "    print(\"Calculating mutations on backbone:\",backbone)\n",
    "    reference_spike_sequence = sequences[backbone]\n",
    "    #calculate mutation differences between node and K lineage\n",
    "    J_indexed_muts = [m for m in get_reference_mutations(ref = sequences[backbone],mut = sequences[ids[len(ids)-1]]) if \"-\" not in m  ] \n",
    "    K_indexed_muts = [m for m in get_mutations(sequences[backbone],sequences[ids[len(ids)-1]]) if \"del\" not in m and '-' not in m  ] \n",
    "    mutation_dictionary  = {k:J_indexed_muts[i] for i,k in enumerate(K_indexed_muts)}\n",
    "    print(\"K->J mutations\")\n",
    "    print(K_indexed_muts)\n",
    "    #loop through each mutation and calculate the scores on the focal node\n",
    "    for mut in mutation_dictionary.keys():\n",
    "        if backbone ==  ids[len(ids)-1]:\n",
    "            sequence = revert_sequence(reference_spike_sequence,[mut])\n",
    "        else:\n",
    "            sequence = mutate_sequence(reference_spike_sequence,[mut])\n",
    "        reference = reference_spike_sequence\n",
    "        mutations = embed_protein_sequences(\n",
    "            [[mut,sequence.replace(\"-\",\"\")]],\n",
    "            reference.replace(\"-\",\"\"),\n",
    "            'S:0',\n",
    "            model,\n",
    "            model_layers,\n",
    "            device,\n",
    "            batch_converter,\n",
    "            alphabet,\n",
    "            scores=True)\n",
    "   \n",
    "        \n",
    "        #append mutation info to dataframe\n",
    "        mut_info = mut_info.append({\"Mutation\":mut,\"rel_grammar\":mutations[mut][\"S:0\"][\"relative_grammaticality\"],\n",
    "                                    \"rel_seq_grammar\":mutations[mut][\"S:0\"][\"relative_sequence_grammaticality\"],\n",
    "                                    \"narrow_seq_grammar\":mutations[mut][\"S:0\"][\"narrow_sequence_grammaticality\"],\n",
    "                                    \"relative_narrow_seq_grammar\":mutations[mut][\"S:0\"][\"relative_narrow_sequence_grammaticality\"],\n",
    "                                    \"semanatic_score\":mutations[mut][\"S:0\"][\"semantic_score\"],\n",
    "                                    \"probability\":mutations[mut][\"S:0\"][\"probability\"],\n",
    "                                    \"Backbone\":backbone},ignore_index=True)\n",
    "        \n",
    "        all_mutations[mut] = mutations\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "mut_info[\"lineage_backbone\"]=mut_info[\"Backbone\"].str.split(\"|\").str[-1]\n",
    "mut_info\n",
    "\n",
    "# print(mut_info.loc[mut_info['Mutation']=='I176K'])\n",
    "# print(mut_info.loc[mut_info['Mutation']=='I151K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "megatable = []\n",
    "\n",
    "for k in mutation_dictionary.keys():\n",
    "    if k == 'Reference':\n",
    "        continue\n",
    "    relative_grammaticality = all_mutations[k][k]['S:0'][\"relative_grammaticality\"]\n",
    "    relative_sequence_grammaticality = all_mutations[k][k]['S:0'][\"relative_sequence_grammaticality\"]\n",
    "    semantic_score = all_mutations[k][k]['S:0'][\"semantic_score\"]\n",
    "\n",
    "    mutations = pd.DataFrame({'mutation':k,\n",
    "                            'relative_grammaticality':relative_grammaticality,\n",
    "                            'relative_sequence_grammaticality':relative_sequence_grammaticality,\n",
    "                            'semantic_score':semantic_score,},index=[0])\n",
    "    mutations.mutations = k\n",
    "    megatable.append(mutations)\n",
    "megatable_df = pd.concat(megatable)\n",
    "\n",
    "if backbone == ids[len(ids)-1]:\n",
    "    for mut in  mutation_dictionary.keys():\n",
    "        megatable_df.mutation = megatable_df.mutation.str.replace(mut,mutation_dictionary[mut])\n",
    "megatable_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler((0,1))\n",
    "\n",
    "megatable_df['scaled_relative_grammaticality'] = mms.fit_transform(-megatable_df.relative_grammaticality.values.reshape(-1,1)).ravel()\n",
    "megatable_df['scaled_relative_sequence_grammaticality'] = mms.fit_transform(-megatable_df.relative_sequence_grammaticality.values.reshape(-1,1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megatable_df.sort_values('relative_grammaticality',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "lsoftmax = torch.nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outside_std(column):\n",
    "    filtered_vals = []\n",
    "    for c in column:\n",
    "        if c >=(column.mean() + (column.std()*2)) or c <= (column.mean() - (column.std()*2)):\n",
    "            filtered_vals.append(c)\n",
    "        else:\n",
    "            filtered_vals.append(np.nan)\n",
    "    return filtered_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_logits_table = []\n",
    "for k in all_mutations.keys():\n",
    "    print(all_mutations[k].keys())\n",
    "    backbone_logits = all_mutations[k]['Reference']['S:0']['Logits']\n",
    "    backbone_logits = format_logits(backbone_logits,alphabet)\n",
    "    backbone_logits = remap_logits(backbone_logits,sequences['Wuhan'], reference_spike_sequence)\n",
    "    backbone_ref_seq_logits = [row[row.Sequence] if row.Sequence != '-' else np.nan for i,row in backbone_logits.iterrows()]\n",
    "\n",
    "    for mutation in all_mutations[k].keys():\n",
    "        if mutation != 'Reference':\n",
    "            if backbone == 'BA.1':\n",
    "                mutated_sequence = revert_sequence(reference_spike_sequence,[mutation])\n",
    "            else:\n",
    "                mutated_sequence = mutate_sequence(reference_spike_sequence,[mutation])\n",
    "\n",
    "            mutated_logits = format_logits(all_mutations[k][mutation]['S:0']['Logits'],alphabet)\n",
    "            mutated_logits = remap_logits(mutated_logits,sequences['Wuhan'], mutated_sequence, )\n",
    "            mutated_seq_logits = [row[row.Sequence]  if row.Sequence != '-' else np.nan for i,row in mutated_logits.iterrows()]\n",
    "            \n",
    "            if backbone == 'BA.1':\n",
    "                # Difference is backbone - mutation here since the \"mutation\" is actually a reversion\n",
    "                difference = np.exp(backbone_ref_seq_logits) -  np.exp(mutated_seq_logits)\n",
    "                pllr =  np.array(backbone_ref_seq_logits)- np.array(mutated_seq_logits)\n",
    "            else:\n",
    "                difference =  np.exp(mutated_seq_logits) - np.exp(backbone_ref_seq_logits)\n",
    "                pllr =  np.array(mutated_seq_logits) - np.array(backbone_ref_seq_logits)\n",
    "\n",
    "            df = pd.DataFrame(\n",
    "                {'source_sequence':list(backbone_logits.Sequence),\n",
    "                'target_sequence':list(mutated_logits.Sequence),\n",
    "                'source_logits':backbone_ref_seq_logits,\n",
    "                'target_logits':mutated_seq_logits,\n",
    "                'change':difference,\n",
    "                'ratio':pllr,\n",
    "                'position':range(1,len(difference)+1)})\n",
    "                \n",
    "            df['masked_change'] =[row.change if row.source_sequence == row.target_sequence else np.nan for i, row in df.iterrows()]\n",
    "            df['masked_ratio'] =[row.ratio if row.source_sequence == row.target_sequence else np.nan for i, row in df.iterrows()]\n",
    "            \n",
    "            local_max_change = df.masked_change.mean()+(df.masked_change.std()*2)\n",
    "            local_min_change = df.masked_change.mean()-(df.masked_change.std()*2)\n",
    "\n",
    "            local_max_ratio = df.masked_ratio.mean()+(df.masked_ratio.std()*2)\n",
    "            local_min_ratio = df.masked_ratio.mean()-(df.masked_ratio.std()*2)\n",
    "\n",
    "            df['significant_masked_change_local'] = [ check_valid(m,local_min_change,local_max_change) for m in df. masked_change]\n",
    "            df['significant_masked_ratio_local'] = [ check_valid(m,local_min_ratio,local_max_ratio) for m in df.masked_ratio]\n",
    "\n",
    "            df['mutation'] = mutation_dictionary[mutation]\n",
    "            reference_logits_table.append(df)\n",
    "reference_logits_table = pd.concat(reference_logits_table,axis=0)\n",
    "\n",
    "max_change = reference_logits_table.masked_change.mean()+(reference_logits_table.masked_change.std()*2)\n",
    "min_change = reference_logits_table.masked_change.mean()-(reference_logits_table.masked_change.std()*2)\n",
    "\n",
    "max_ratio = reference_logits_table.masked_ratio.mean()+(reference_logits_table.masked_ratio.std()*2)\n",
    "min_ratio = reference_logits_table.masked_ratio.mean()-(reference_logits_table.masked_ratio.std()*2)\n",
    "\n",
    "reference_logits_table['significant_masked_change'] = [ check_valid(m,min_change,max_change) for m in reference_logits_table.masked_change]\n",
    "reference_logits_table['significant_masked_ratio'] = [ check_valid(m,min_ratio,max_ratio) for m in reference_logits_table.masked_ratio]\n",
    "\n",
    "max_change = reference_logits_table.masked_change.round(4).mean()+(reference_logits_table.masked_change.round(4).std()*2)\n",
    "min_change = reference_logits_table.masked_change.round(4).mean()-(reference_logits_table.masked_change.round(4).std()*2)\n",
    "\n",
    "reference_logits_table['significant_masked_change_rounded'] = [ check_valid(m,min_change,max_change) for m in reference_logits_table.masked_change.round(4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(reference_logits_table, x=\"position\", y=\"masked_change\",color=\"mutation\", facet_col='mutation',facet_col_wrap=6,height=1000, width=1500, hover_data=['position','change','mutation'])\n",
    "fig.update_traces(marker={'size': 3})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(reference_logits_table, x=\"position\", y=\"significant_masked_change_rounded\",color=\"mutation\", facet_col='mutation',facet_col_wrap=6,height=1000, width=1500, hover_data=['position','change','mutation'])\n",
    "fig.update_traces(marker={'size': 3})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_logits_table.to_csv('./Epistasis/Revisions_Omicron_Epistasis.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_logits_table = pd.read_csv('./Epistasis/Revisions_Omicron_Epistasis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_change = reference_logits_table.masked_change.mean()+(reference_logits_table.masked_change.std())\n",
    "min_change = reference_logits_table.masked_change.mean()-(reference_logits_table.masked_change.std())\n",
    "reference_logits_table['single_significant_masked_change'] = [ check_valid(m,min_change,max_change) for m in reference_logits_table.masked_change]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_logits_table.to_csv('Revisions_Omicron_Epistasis_with_single_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(reference_logits_table, x=\"position\", y=\"single_significant_masked_change\",color=\"mutation\", facet_col='mutation',facet_col_wrap=6,height=1000, width=1500, hover_data=['position','change','mutation'])\n",
    "fig.update_traces(marker={'size': 3})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba1_mutated_positions = reference_logits_table.mutation.str[1:-1].astype(int).unique()\n",
    "ba1_mutated_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_std_identified_interactions = reference_logits_table[(reference_logits_table.single_significant_masked_change.isna() == False) & (reference_logits_table.position.isin(ba1_mutated_positions)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_std_identified_interactions = reference_logits_table[(reference_logits_table.significant_masked_change.isna() == False) & (reference_logits_table.position.isin(ba1_mutated_positions)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(two_std_identified_interactions,x=two_std_identified_interactions.position.astype(str),y=two_std_identified_interactions.mutation.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(one_std_identified_interactions,x=one_std_identified_interactions.position.astype(str),y=one_std_identified_interactions.mutation.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_interactions = one_std_identified_interactions[['position','mutation']]\n",
    "identified_interactions['mutated_position'] = identified_interactions.mutation.str[1:-1].astype(int)\n",
    "swap_interactions = identified_interactions[identified_interactions.position < identified_interactions.mutated_position]\n",
    "swap_interactions.rename(columns={'position':'position_1','mutated_position':'position_2'},inplace=True)\n",
    "swap_interactions_2 = identified_interactions[identified_interactions.position >= identified_interactions.mutated_position]\n",
    "swap_interactions_2.rename(columns={'mutated_position':'position_1','position':'position_2'},inplace=True)\n",
    "\n",
    "swap_interactions = pd.concat([swap_interactions,swap_interactions_2])\n",
    "swap_interactions.to_csv('Omicron_One_Std_Interactions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_interactions = two_std_identified_interactions[['position','mutation']]\n",
    "identified_interactions['mutated_position'] = identified_interactions.mutation.str[1:-1].astype(int)\n",
    "swap_interactions = identified_interactions[identified_interactions.position < identified_interactions.mutated_position]\n",
    "swap_interactions.rename(columns={'position':'position_1','mutated_position':'position_2'},inplace=True)\n",
    "swap_interactions_2 = identified_interactions[identified_interactions.position >= identified_interactions.mutated_position]\n",
    "swap_interactions_2.rename(columns={'mutated_position':'position_1','position':'position_2'},inplace=True)\n",
    "\n",
    "swap_interactions = pd.concat([swap_interactions,swap_interactions_2])\n",
    "swap_interactions.to_csv('Omicron_Two_Std_Interactions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plm_sars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
